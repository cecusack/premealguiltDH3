---
title: "MealtimeEmotions"
output: html_document
date: "2023-01-16"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# libs and dat
```{r}
# clear workspace
# rm(list=ls())

if (!require("tidyverse")) {install.packages("tidyverse"); require("tidyverse")} # tidy
if (!require("psych")) {install.packages("psych"); require("psych")} # descriptives
if (!require("lme4")) {install.packages("lme4"); require("lme4")} # fits mixed models
if (!require("nlme")) {install.packages("nlme"); require("nlme")} # for fitting multiple groups / heteroscedastic model
if (!require("lmerTest")) {install.packages("lmerTest"); require("lmerTest")} # provides t-tests for fixed effects
if (!require("performance")) {install.packages("performance"); require("performance")} # computes ICC
if (!require("DataCombine")) {install.packages("DataCombine"); require("DataCombine")} # leadingDataCombine
# library(plyr)
library(sjPlot)
library(multcomp)
library(psychometric)
library(EMAtools)
library(r2mlm)

dat_import <- read.csv("dat.csv", header = TRUE, sep=",")
dat <- dat_import
length(unique(dat$unique_id)) # 108
```

# data management
```{r}
DH3_imeans <- plyr::ddply(dat, "unique_id", summarize,
                    anx_trait = mean(anx, na.rm = TRUE),
                    guilt_trait = mean(guilt, na.rm = TRUE),
                    avoidemo_trait = mean(avoidemo, na.rm = TRUE),
                    physuncomfort_trait = mean(physuncomfort, na.rm = TRUE))

# describe(DH3_imeans) 
dat <- merge(dat, DH3_imeans, by="unique_id") # merge the EMA trait items into the self-report data
# head(dat)

####### center trait vars to compare between persons later #######
dat$cent_anx <- c(scale(dat$anx_trait,center=TRUE,scale=FALSE))
dat$cent_guilt <- c(scale(dat$guilt_trait,center=TRUE,scale=FALSE))
dat$cent_avoid <- c(scale(dat$avoidemo_trait,center=TRUE,scale=FALSE))
dat$cent_phys <- c(scale(dat$physuncomfort_trait,center=TRUE,scale=FALSE))
# describe(dat)

####### create state vars #######
dat$anx_state <- dat$anx - dat$anx_trait
dat$guilt_state <- dat$guilt - dat$guilt_trait
dat$avoid_state <- dat$avoidemo - dat$avoidemo_trait
dat$phys_state <- dat$physuncomfort - dat$physuncomfort_trait
# head(dat)

####### lead #######
dat <- slide(data=dat, Var="anx", TimeVar="beep", GroupVar="unique_id", NewVar="anx_lead", slideBy=1)
dat <- slide(data=dat, Var="guilt", TimeVar="beep", GroupVar="unique_id", NewVar="guilt_lead", slideBy=1)
dat <- slide(data=dat, Var="avoidemo", TimeVar="beep", GroupVar="unique_id", NewVar="avoid_lead", slideBy=1)
dat <- slide(data=dat, Var="physuncomfort", TimeVar="beep", GroupVar= "unique_id", NewVar="phys_lead", slideBy=1)

# write.csv(dat, "mlmdat_statetraitcent.csv", row.names = FALSE)
rm(DH3_imeans)
```

# anxiety-avoidance cycle
## anx to avoid
```{r}
#### ICC ####
ICC1.lme(avoid_lead, unique_id, data=dat) # 0.65

#### intercept only model ####
avoid1 = lme(avoid_lead ~ 1,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(avoid1)

#### model 2: add level 1 effects of state variables and emotional avoidance at the previous time point (level 1 = observation level) ####
avoid2 = lme(avoid_lead ~ 1 + avoidemo + anx_state,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(avoid2)

#### model 3: add level 2 effects ####
avoid3 = lme(avoid_lead ~ 1 + avoidemo + anx_state + cent_anx,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(avoid3)
intervals(avoid3)

#### model 4: add random slopes for state variables ####
avoid4 = lme(avoid_lead ~ 1 + avoidemo + anx_state + cent_anx,
            random =~ 1 + anx_state|unique_id,
            data=dat,
            na.action = na.exclude)
summary(avoid4)
intervals(avoid4)
# anova(avoid3, avoid4)

## effect size
lme.dscore(avoid4, dat, "nlme")

## pseudo R squared
r2mlm(avoid4, bargraph = TRUE)

# get SE for random effects
exp(attr(avoid4$apVar, "Pars"))^2

qqnorm(avoid4, ~ranef(., level=1))
plot(avoid4)
```

### avoid to anx
```{r}
#### ICC ####
ICC1.lme(anx_lead, unique_id, data=dat) # 0.54

#### intercept only model ####
anx1 = lme(anx_lead ~ 1,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(anx1)

#### model 2: add level 1 effects of state variables and emotional avoidance at the previous time point (level 1 = observation level) ####
anx2 = lme(anx_lead ~ 1 + anx + avoid_state,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(anx2)

#### model 3: add level 2 effects ####
anx3 = lme(anx_lead ~ 1 + anx + avoid_state + cent_avoid,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(anx3)
intervals(anx3)
exp(attr(avoid3$apVar, "Pars"))^2

#### model 4: add random slopes for state variables ####
anx4 = lme(anx_lead ~ 1 + anx + avoid_state + cent_avoid,
            random =~ 1 + avoid_state|unique_id,
            data=dat,
            na.action = na.exclude)
summary(anx4)
intervals(anx4) # NPD too complex go back to anx 3

## effect size
lme.dscore(anx3, dat, "nlme")


## pseudo R squared
r2mlm(anx3, bargraph = TRUE)

qqnorm(anx3, ~ranef(., level=1))
plot(anx3)
```

## anx and guilt to emo avoid
```{r}
#### model 2: add level 1 effects of state variables and emotional avoidance at the previous time point (level 1 = observation level) ####
avoidcomb = lme(avoid_lead ~ 1 + avoidemo + anx_state +guilt_state,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(avoidcomb)

#### model 3: add level 2 effects ####
avoidcomb2 = lme(avoid_lead ~ 1 + avoidemo + anx_state + cent_anx + guilt_state+cent_guilt,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(avoidcomb2)
intervals(avoidcomb2)

#### model 4: add random slopes for state variables ####
avoidcomb3 = lme(avoid_lead ~ 1 + avoidemo + anx_state + cent_anx+ guilt_state+cent_guilt,
            random =~ 1 + anx_state+guilt_state|unique_id,
            data=dat,
            na.action = na.exclude)
summary(avoidcomb3)
intervals(avoidcomb3)
# anova(avoidcomb2, avoidcomb3)

## effect size
lme.dscore(avoidcomb3, dat, "nlme")


## pseudo R squared
r2mlm(avoidcomb3, bargraph = TRUE)
qqnorm(avoidcomb3, ~ranef(., level=1))
plot(avoidcomb3)
```

### vice versa
```{r}
guilt1 = lme(guilt_lead ~ 1,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(guilt1)

#### model 2: add level 1 effects of state variables and emotional avoidance at the previous time point (level 1 = observation level) ####
guilt2 = lme(guilt_lead ~ 1 + guilt + avoid_state,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(guilt2)

#### model 3: add level 2 effects ####
guilt3 = lme(guilt_lead ~ 1 + guilt + avoid_state + cent_avoid,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(guilt3)
intervals(guilt3)

#### model 4: add random slopes for state variables ####
guilt4 = lme(guilt_lead ~ 1 + guilt + avoid_state + cent_avoid,
            random =~ 1 + avoid_state|unique_id,
            data=dat,
            na.action = na.exclude)
summary(guilt4)
intervals(guilt4)
anova(guilt3, guilt4)

## effect size
lme.dscore(guilt4, dat, "nlme")

## pseudo R squared
r2mlm(guilt4, bargraph = TRUE)

qqnorm(guilt4, ~ranef(., level=1))
plot(guilt4)
```

# physical pathways to avoidance
```{r}
#### model 2: add level 1 effects of state variables and emotional avoidance at the previous time point (level 1 = observation level) ####
avoid_phys = lme(avoid_lead ~ 1 + avoidemo + phys_state,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(avoid_phys)

### add level 2 ###
avoid_phys2 = lme(avoid_lead ~ 1 + avoidemo + phys_state+cent_phys,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(avoid_phys2)
intervals(avoid_phys2)

### add random slopes ###
avoid_phys3 = lme(avoid_lead ~ 1 + avoidemo + phys_state+cent_phys,
            random =~ 1 + phys_state|unique_id,
            data=dat,
            na.action = na.exclude)
# summary(avoid_phys3)
# intervals(avoid_phys3)
# anova(avoid_phys2, avoid_phys3)

## effect size
lme.dscore(avoid_phys2, dat, "nlme")

## pseudo R squared
r2mlm(avoid_phys2, bargraph = TRUE)
qqnorm(avoid_phys2, ~ranef(., level=1))
plot(avoid_phys2)
```

## vice versa
```{r}
#### ICC ####
ICC1.lme(phys_lead, unique_id, data=dat) # 0.65
ICC1.lme(guilt_lead, unique_id, data=dat) # 0.53

#### intercept only model ####
phys1 = lme(phys_lead ~ 1,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(phys1)

#### model 2: add level 1 effects of state variables and emotional avoidance at the previous time point (level 1 = observation level) ####
phys2 = lme(phys_lead ~ 1 + physuncomfort + avoid_state,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(phys2)

#### model 3: add level 2 effects ####
phys3 = lme(phys_lead ~ 1 + physuncomfort + avoid_state + cent_avoid,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(phys3)
intervals(phys3)

#### model 4: add random slopes for state variables ####
phys4 = lme(phys_lead ~ 1 + physuncomfort + avoid_state + cent_avoid,
            random =~ 1 + avoid_state|unique_id,
            data=dat,
            na.action = na.exclude)
summary(phys4)
intervals(phys4) # NPD too complex go back to phys3 
anova(phys3, phys4)

## effect size
lme.dscore(phys3, dat, "nlme")


## pseudo R squared
r2mlm(phys3, bargraph = TRUE)

qqnorm(phys3, ~ranef(., level=1))
plot(phys3)
```

# emo to phys
## phys to anx
```{r}
# random intercept
summary(anx1)

anx_phys = lme(anx_lead ~ 1 + anx + phys_state,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(anx_phys)

### add level 2 ###
anx_phys2 = lme(anx_lead ~ 1 + anx + phys_state+cent_phys,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(anx_phys2)
intervals(anx_phys2)

### add random slopes ###
anx_phys3 = lme(anx_lead ~ 1 + anx + phys_state+cent_phys,
            random =~ 1 + phys_state|unique_id,
            data=dat,
            na.action = na.exclude)
summary(anx_phys3)
intervals(anx_phys3)
# anova(anx_phys2, anx_phys3)

## effect size
lme.dscore(anx_phys3, dat, "nlme")


## pseudo R squared
r2mlm(anx_phys3, bargraph = TRUE)

qqnorm(anx_phys3, ~ranef(., level=1))
plot(anx_phys3)
```

## phys to guilt
```{r}
# random intercept 
summary(guilt1)

guilt_phys = lme(guilt_lead ~ 1 + guilt + phys_state,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(guilt_phys)

### add level 2 ###
guilt_phys2 = lme(guilt_lead ~ 1 + guilt + phys_state+cent_phys,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(guilt_phys2)
intervals(guilt_phys2)

### add random slopes ###
guilt_phys3 = lme(guilt_lead ~ 1 + guilt + phys_state+cent_phys,
            random =~ 1 + phys_state|unique_id,
            data=dat,
            na.action = na.exclude)
summary(guilt_phys3)
intervals(guilt_phys3) 

# anova(guilt_phys2, guilt_phys3) # go to more parsimonious model

## effect size
lme.dscore(guilt_phys3, dat, "nlme")


## pseudo R squared
r2mlm(guilt_phys2, bargraph = TRUE)

qqnorm(guilt_phys2, ~ranef(., level=1))
plot(guilt_phys2)
```

## anx guilt to phys
```{r}
emophyscomb = lme(phys_lead ~ 1 + physuncomfort + anx_state +guilt_state,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(emophyscomb)

#### model 3: add level 2 effects ####
emophyscomb2 = lme(phys_lead ~ 1 + physuncomfort + anx_state + cent_anx + guilt_state+cent_guilt,
            random =~ 1|unique_id,
            data=dat,
            na.action = na.exclude)
summary(emophyscomb2)
intervals(emophyscomb2)

#### model 4: add random slopes for state variables ####
emophyscomb3 = lme(phys_lead ~ 1 + physuncomfort + anx_state + cent_anx+ guilt_state+cent_guilt,
            random =~ 1 + anx_state+guilt_state|unique_id,
            data=dat,
            na.action = na.exclude)
summary(emophyscomb3)
intervals(emophyscomb3)
# anova(emophyscomb2, emophyscomb3)


## effect size
lme.dscore(emophyscomb3, dat, "nlme")


## pseudo R squared
r2mlm(emophyscomb3, bargraph = TRUE)


qqnorm(emophyscomb3, ~ranef(., level=1))
plot(emophyscomb3)
```

# corrs
```{r}
cors <- corr.test(dat[c(8:10,13,31:34)])
cors$r
min(cors$r)
max(cors$r)
cors$r[c(1:4), c(1:4)]
cors$p[c(1:4), c(1:4)]
```

# network
## preprocess
```{r}
library(mlVAR) # for estimating network
library(qgraph) # for visualizing network

net_dat <- dat[which(dat$beep<5),]

net_dat <- net_dat %>% dplyr::rename(physdis=physuncomfort, anxiety=anx)

dayvar = "day"
beepvar = "beep"

names.vars <- c("anxiety", "guilt", "physdis", "avoidemo")
dir.create("./NetResultsJan2023")
dir.create("./NetResultsJan2023/Figs")
```

## estimate

```{r}
fit <- mlVAR(net_dat, vars=names.vars, idvar="unique_id", beepvar=beepvar, dayvar=dayvar, lags = 1,
             temporal = "correlated", estimator = "lmer", contemporaneous = "correlated", nCores = 1, verbose = TRUE,
             scale = TRUE, scaleWithin = FALSE, AR = FALSE,
             MplusSave = TRUE, MplusName = "mlVAR", iterations = "(2000)",
             chains = nCores)

summary(fit)
summary(fit)[1] # temporal
summary(fit)[2] # contemporaneous
summary(fit)[3] # between
write.csv(summary(fit)[1], "./NetResultsJan2023/modefit_pdc.csv", row.names = FALSE)
write.csv(summary(fit)[2], "./NetResultsJan2023/modefit_pcc.csv", row.names = FALSE)
write.csv(summary(fit)[3], "./NetResultsJan2023/modefit_btwn.csv", row.names = FALSE)

#### temporal network plot ####
pdf("./NetResultsJan2023/Figs/temporalnetwork.pdf")
pdc <- plot(fit, "temporal", nonsig = "hide", label.cex=1.3, alpha="0.05",
          vsize=9, legend=F, edge.labels = TRUE, edge.label.position
=.6, color=c('#b4dced'), mar=c(5,3,3,3))
dev.off()

# centrality plot
pdf("./NetResultsJan2023/Figs/pdc_centplot.pdf")
pdc_cent <- pdc %>% 
  # centrPlot() +
  centralityPlot()+
  theme(legend.position = "none") +
 # facet_grid(rows = vars(measure)) +
  theme(axis.text=element_text(size=13),
      #  strip.text.y = element_text(size=15),
        strip.text.x = element_text(size = 15),
      axis.text.x = element_text(angle = 90))+
  scale_x_continuous(
  labels = scales::number_format(accuracy = 0.01))
dev.off()
ggsave("./NetResultsJan2023/Figs/pdc_centplot.png", pdc_cent)

pdc_cent_h <- 
  pdc %>% 
  # centrPlot() +
  centPlot_cec()+
    facet_grid(rows = vars(measure))+
  theme(legend.position = "none") +
 # facet_grid(rows = vars(measure)) +
  theme(axis.text=element_text(size=13),
      #  strip.text.y = element_text(size=15),
        strip.text.x = element_text(size = 15),
      axis.text.x = element_text(angle = 90))+
  scale_x_continuous(
  labels = scales::number_format(accuracy = 0.01))

ggsave("./NetResultsJan2023/Figs/pdc_centplothorizontal.png", pdc_cent_h, width = 10, height=6)

# centralityTable(pdc)
test=as.data.frame(centrality_auto(pdc)[1])
write.csv(test, "./NetResultsJan2023/temporal centrality.csv", row.names = TRUE)

centrality_auto(pdc)
# edges
# getWmat(pdc)
write.csv(getWmat(pdc), "./NetResultsJan2023/edges_pdc.csv", row.names = FALSE)

# greatest in strength anxiety = .15
# greatest out strength avoid emotions = .12

#### contemporaneous network plot ####
pdf("./NetResultsJan2023/Figs/contemporaneousnetwork.pdf")
pcc <- plot(fit, "contemporaneous", nonsig = "hide", rule = "or", label.cex=1.3,
          vsize=9, legend=F, alpha="0.05",edge.labels = TRUE,
          color=c('#b4dced'))
dev.off()

# centrality plot
pdf("./NetResultsJan2023/Figs/pcc_centplot.pdf")
pdc_cent <- pcc %>% 
  # centrPlot() +
  centralityPlot()+
  theme(legend.position = "none") +
 # facet_grid(rows = vars(measure)) +
  theme(axis.text=element_text(size=13),
      #  strip.text.y = element_text(size=15),
        strip.text.x = element_text(size = 15),
      axis.text.x = element_text(angle = 90))
dev.off()

test2=as.data.frame(centrality_auto(pcc)[1])
write.csv(test2, "./NetResultsJan2023/contemporaneous centrality.csv", row.names = TRUE)

# edges
# getWmat(pcc_imp)
write.csv(getWmat(pcc), "./NetResultsJan2023/edges_pcc.csv", row.names = FALSE)
```

# behavior net
```{r}
net_dat <- dat[which(dat$beep<5),]

net_dat <- net_dat %>% dplyr::rename(physdis=physuncomfort, anxiety=anx)

dayvar = "day"
beepvar = "beep"

names.vars <- c("anxiety", "guilt", "physdis", "avoidemo", "restrict", "overeat", "fowg", "vomit")

fit2 <- mlVAR(net_dat, vars=names.vars, idvar="unique_id", beepvar=beepvar, dayvar=dayvar, lags = 1,
             temporal = "correlated", estimator = "lmer", contemporaneous = "correlated", nCores = 1, verbose = TRUE,
             scale = TRUE, scaleWithin = FALSE, AR = FALSE,
             MplusSave = TRUE, MplusName = "mlVAR", iterations = "(2000)",
             chains = nCores)

summary(fit2)
summary(fit2)[1] # temporal
summary(fit2)[2] # contemporaneous
summary(fit2)[3] # between
write.csv(summary(fit2)[1], "./NetResultsJan2023/modefitbx_pdc.csv", row.names = FALSE)
write.csv(summary(fit2)[2], "./NetResultsJan2023/modefitbx_pcc.csv", row.names = FALSE)
write.csv(summary(fit2)[3], "./NetResultsJan2023/modefitbx_btwn.csv", row.names = FALSE)

#### temporal network plot ####
pdf("./NetResultsJan2023/Figs/temporalnetworkbx.pdf")
pdc2 <- plot(fit2, "temporal", nonsig = "hide", label.cex=1.3, alpha="0.05",
          vsize=9, legend=F, edge.labels = TRUE, edge.label.position
=.6, color=c('#b4dced'), mar=c(5,3,3,3))
dev.off()

# centrality plot
pdf("./NetResultsJan2023/Figs/pdc_centplotbx.pdf")
pdc_cent2 <- pdc2 %>% 
  # centrPlot() +
  centralityPlot()+
  theme(legend.position = "none") +
 # facet_grid(rows = vars(measure)) +
  theme(axis.text=element_text(size=13),
      #  strip.text.y = element_text(size=15),
        strip.text.x = element_text(size = 15),
      axis.text.x = element_text(angle = 90))+
  scale_x_continuous(
  labels = scales::number_format(accuracy = 0.01))
dev.off()
ggsave("./NetResultsJan2023/Figs/pdc_centplotbx.png", pdc_cent2)

centrality_auto(pdc2)[1]

getWmat(pdc2)
```